{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. SDKを使って複数のCSVファイルをアップロードしてみよう\n",
    "このチュートリアルでは、**intdash SDK for Python** （以下、intdash SDKと呼びます）を使用して多数のCSVファイルをアップロードする方法を紹介します。\n",
    "今回のケースでは、CSVファイル1ファイルごとに1つの計測を作成します。CSVファイルのフォーマットについては、以下の「事前準備」を参考にしてください。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.0 事前準備\n",
    "本シナリオを実施する前に、以下を用意する必要があります。\n",
    "\n",
    "- データ登録用のエッジ\n",
    "- アップロードする複数のCSV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### 使用データ\n",
    "本チュートリアルでは、以下のデータをサーバー側に準備する必要があります。  \n",
    "本項では以下のデータ名で処理を実施しています。\n",
    "\n",
    "|データ項目|本シナリオで登場するデータ名|\n",
    "|:---|:---|\n",
    "|時系列データを登録するエッジ|edge1|\n",
    "|時系列データが格納されたCSV| sampleX.csv （X = 任意の数字）|\n",
    "\n",
    "#### アップロードするCSVデータの詳細\n",
    "\n",
    "今回アップロードするCSVは、以下の条件を満たすものとします。\n",
    " * 第1行は、各列の名称を文字列で格納していること\n",
    " * 第1列は、タイムスタンプを格納していること\n",
    " * 第2列目以降には、各列名ごとのデータを格納していること\n",
    "\n",
    "<img src=\"https://github.com/aptpod/aws-marketplace-tutorials/blob/master/img/img1.png?raw=true\\\">\n",
    "\n",
    "第1行に記載されている名称をデータの名前（ `data_id` ）として使用します。\n",
    "\n",
    "### アップロードするCSVファイルの配置\n",
    "登録する対象となる時系列データが格納された複数のCSVファイルは、本Jupyter Notebookと同じディレクトリに存在する `csv` ディレクトリ配下に配置します。本チュートリアルでは、既に配置されているサンプルのCSVファイルを用いて実施しています。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### パッケージのimportとクライアントの生成\n",
    "`intdash.Client` に与える `url` は intdashサーバーの環境情報から、`username` と `password` はログイン用エッジで発行したアクセス情報を指定してください。  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import math\n",
    "\n",
    "import intdash\n",
    "from intdash import timeutils\n",
    "\n",
    "# Create client\n",
    "client = intdash.Client(\n",
    "    url = \"https://example.intdash.jp\",\n",
    "    username = \"edge1\",\n",
    "    password=\"password_here\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "以上で事前準備は終了です。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1 データのアップロードに使用するエッジを取得する\n",
    "まず最初に、CSVファイルをアップロードする際に使用するエッジを取得します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "edges = client.edges.list(name='edge1')\n",
    "edge1 = edges[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'edge1'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "edge1.name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2 CSVファイルを取得する\n",
    "各CSVファイルを `pandas.DataFrame` として読み込みます。ここでは `csv/` ディレクトリに格納されているCSVファイルを対象にします。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob \n",
    "\n",
    "csv_files = glob.glob('./csv/*')\n",
    "\n",
    "dfs = []\n",
    "\n",
    "for csv_path in csv_files:\n",
    "    df = pd.read_csv(csv_path, index_col=0).groupby(\"time\").last()\n",
    "    dfs.append(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.3 CSVファイルごとに計測を作成し、データを登録する\n",
    "ここからは1つのCSVファイルごとの処理に焦点をあてて解説します。これらの処理を繰り返すことで、複数のCSVファイルをアップロードすることができます。  \n",
    "※ すぐに複数ファイルを処理したい場合、本節をスキップしてください。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pick first DataFrame.\n",
    "df = dfs.pop(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "データの最初の時刻を計測の開始時刻とし、計測を作成します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_measurements = client.measurements.create(\n",
    "    name='csv_data',  # Define name of measurement.\n",
    "    basetime=timeutils.str2timestamp(df.index[0]), #  Use timestamp of the first datapoint as the basetime of the measurement.\n",
    "    edge_uuid=edge1.uuid\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "計測の生成後、DataFrameを `DataPoint` 形式に変換します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "datapoints = []\n",
    "\n",
    "for data_id, values in df.to_dict().items():\n",
    "    for time, value in values.items():\n",
    "        \n",
    "        if math.isnan(value) or value is '':\n",
    "            continue\n",
    "            \n",
    "        datapoints.append(\n",
    "            intdash.DataPoint(\n",
    "                elapsed_time= timeutils.str2timestamp(time) - new_measurements.basetime, # Time elapsed from the start of measurement.\n",
    "                data_type=intdash.DataType.float,\n",
    "                channel=1, # fixed at 1.\n",
    "                data_payload=intdash.data.Float(data_id=data_id, value=value).to_payload()\n",
    "            )\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "変換が完了したら、先程作成した計測に時系列データを紐付けます。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "client.data_points.store(\n",
    "    measurement_uuid=new_measurements.uuid,\n",
    "    data_points=datapoints\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "これで1つのCSVデータのアップロードが完了しました。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.4 複数CSVファイルに対してまとめて登録処理を行う\n",
    "以下は、前節の処理を1つにまとめ、複数のDataFrameに対して繰り返し処理をおこなっています。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "for df in dfs:\n",
    "    # Create a measurement.\n",
    "    new_measurements = client.measurements.create(\n",
    "        name='csv_data',  # Define name of measurement.\n",
    "        basetime=timeutils.str2timestamp(df.index[0]), #  Use timestamp of the first datapoint as the basetime of the measurement.\n",
    "        edge_uuid=edge1.uuid\n",
    "    )\n",
    "    \n",
    "    # Convert DataFrames to DataPoints.\n",
    "    datapoints = []\n",
    "\n",
    "    for data_id, values in df.to_dict().items():\n",
    "        for time, value in values.items():\n",
    "            \n",
    "            if math.isnan(value) or value is '':\n",
    "                continue\n",
    "\n",
    "            datapoints.append(\n",
    "                intdash.DataPoint(\n",
    "                    elapsed_time= timeutils.str2timestamp(time) - new_measurements.basetime, # Time elapsed from the start of measurement.\n",
    "                    data_type=intdash.DataType.float,\n",
    "                    channel=1, # fixed at 1.\n",
    "                    data_payload=intdash.data.Float(data_id=data_id, value=value).to_payload()\n",
    "                )\n",
    "            )\n",
    "            \n",
    "    # Store datapoints.\n",
    "    client.data_points.store(\n",
    "        measurement_uuid=new_measurements.uuid,\n",
    "        data_points=datapoints\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "上記を実行すると、複数のCSVファイルをアップロードすることができます。\n",
    "Visual M2M Data Visualizerで[Stored Data]を確認すると、計測が登録されていることが確認できます。\n",
    "<img src=\"https://github.com/aptpod/aws-marketplace-tutorials/blob/master/img/img3.png?raw=true\\\">"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
