{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4.  スマートフォンの伝送データを画像ファイルとして保存してみよう\n",
    "\n",
    "このチュートリアルでは、iOSアプリケーション **Visual M2M Motion**  （以下、VM2M Motion とします）からストリーミングされた動画データを画像として保存します。このケースでは、以下の方法を中心に解説します。\n",
    "\n",
    "* サーバー側に保存されたM-JPEGデータをバイナリデータとして取得する\n",
    "* 画像ファイル(.jpg)として保存する\n",
    "\n",
    "## 4.0 事前準備\n",
    "本シナリオを実施する前に、以下を用意する必要があります。\n",
    "\n",
    "- 計測用のエッジ\n",
    "-  VM2M Motionアプリでアップロードした計測（画像を含む）\n",
    "\n",
    "\n",
    "### 使用データ\n",
    "本シナリオでは、事前に以下のデータをサーバー側に準備する必要があります。  \n",
    "\n",
    "|データ項目|本シナリオで登場するデータ名|\n",
    "|:---|:---|\n",
    "|時系列データを登録するエッジ|edge1|\n",
    "|計測情報 (※)|計測名は登場なし|\n",
    "\n",
    "(※) 使用する時系列データは **intdashチュートリアル2A：スマートフォンの伝送データをリアルタイムに可視化してみよう** と同様に、 VM2M Motion を使用して時系列データを登録します。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 計測データの作成と時系列データのアップロード\n",
    "**Visual M2M Motion** を使用してデータをアップロードします。 計測を登録後、計測が新しく生成されたことを **Data Visualizer** で確認してください。\n",
    "\n",
    "アップロード方法については、 **intdashチュートリアル2A：スマートフォンの伝送データをリアルタイムに可視化してみよう** を参照してください。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data Visualizerの[Stored Data]に計測が表示されていれば完了です。\n",
    "\n",
    "<img src=\"https://user-images.githubusercontent.com/70192465/94385045-103f7280-017f-11eb-8f12-30df59079069.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### パッケージのimportとクライアントの生成\n",
    "`intdash.Client` に与える `url` は intdashサーバーの環境情報から、`username` と `password` はログイン用エッジで発行したアクセス情報を指定してください。  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "import intdash\n",
    "from intdash import timeutils\n",
    "\n",
    "# Create client\n",
    "client = intdash.Client(\n",
    "    url = \"https://example.intdash.jp\",\n",
    "    username = \"edge1\",\n",
    "    password=\"password_here\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "これで、事前準備は終了です。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.1 計測に使用したエッジを取得する\n",
    "VM2M Motionでログインした際に使用したエッジを取得します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "edges = client.edges.list(name='edge1')\n",
    "edge1 = edges[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'edge1'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "edge1.name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.2 時系列データを取得する\n",
    "本シナリオでは、時系列データの取得には `client.data_points` エンドポイントを使用します。信号定義からデータを取得する場合、通常は ``labels`` を指定しますが、本ケースでは信号定義を使用しないため、 `id_queries` で取得します。   \n",
    "`start` および `end` は前述の手順で作成した計測を含む時刻に変更してください。\n",
    "\n",
    "※通常は ``data_id`` を指定しますが、JPEGデータの場合は ``data_id`` が固定されているため指定する必要はありません。詳細は、ドキュメント記載の [intdash.data.Jpeg](https://docs.intdash.jp/sdk/python/latest/ja/data.html#intdash.data.JPEG)を確認してください。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "dps = client.data_points.list(\n",
    "    edge_name='edge1',\n",
    "    start=timeutils.str2timestamp('2020-07-17 00:00:00+09:00'), # change appropriately.\n",
    "    end=timeutils.str2timestamp('2020-07-18 00:00:00+09:00'),  # change appropriately.\n",
    "    id_queries=[\n",
    "        intdash.IdQuery(\n",
    "            data_type=intdash.DataType.jpeg,\n",
    "            channel=1\n",
    "        )\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.3 取得したデータを画像ファイルとして保存する\n",
    "取得したバイナリデータを、そのままJPEGとして保存します。\n",
    "ここではサンプルとして、取得した時系列データのうち、最初のデータポイントのみを保存します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = dps[0] #  Get the first data.\n",
    "\n",
    "with open(f'./{pd.Timestamp(data.time).value}.jpg', 'wb') as fout:\n",
    "    # Use the timestamp as the filename.\n",
    "    fout.write(data.data_payload)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "すべてのデータポイントの画像を保存したい場合は、上記を繰り返します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "\n",
    "save_dir='./images'\n",
    "\n",
    "for d in dps:\n",
    "    \n",
    "    if not os.path.isdir(save_dir):\n",
    "            os.makedirs(save_dir)\n",
    "            \n",
    "    # Use the timestamp as the filename.\n",
    "    with open(f'{save_dir}/{pd.Timestamp(d.time).value}.jpg', 'wb') as fout:\n",
    "        fout.write(d.data_payload)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
